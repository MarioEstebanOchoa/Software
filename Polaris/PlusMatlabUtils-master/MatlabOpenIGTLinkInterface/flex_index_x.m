function [y1] = flex_index_x(x1)
%FLEX_INDEX_X neural network simulation function.
%
% Auto-generated by MATLAB, 29-Jul-2019 11:11:50.
% 
% [y1] = flex_index_x(x1) takes these arguments:
%   x = 1xQ matrix, input #1
% and returns:
%   y = 1xQ matrix, output #1
% where Q is the number of samples.

%#ok<*RPMT0>

% ===== NEURAL NETWORK CONSTANTS =====

% Input 1
x1_step1.xoffset = 50.4446115060186;
x1_step1.gain = 0.111926515648932;
x1_step1.ymin = -1;

% Layer 1
b1 = [0.0088410438158547013238;-0.011936619420033420247;-0.33013795252009597858;-0.008301364376861700145;0.0075708706734114467746];
IW1_1 = [-0.060332190388251237534;0.088620893657471777605;-0.62215090607510770138;0.056141295538276528299;-0.0506604216854561612];

% Layer 2
b2 = -0.15667570990233598005;
LW2_1 = [-0.061285822386277923057 0.090394655672859813844 -0.64467921712444742344 0.057001072128472211886 -0.051406339019425956183];

% Output 1
y1_step1.ymin = -1;
y1_step1.gain = 0.273671106995872;
y1_step1.xoffset = 25.3760075692885;

% ===== SIMULATION ========

% Dimensions
Q = size(x1,2); % samples

% Input 1
xp1 = mapminmax_apply(x1,x1_step1);

% Layer 1
a1 = tansig_apply(repmat(b1,1,Q) + IW1_1*xp1);

% Layer 2
a2 = repmat(b2,1,Q) + LW2_1*a1;

% Output 1
y1 = mapminmax_reverse(a2,y1_step1);
end

% ===== MODULE FUNCTIONS ========

% Map Minimum and Maximum Input Processing Function
function y = mapminmax_apply(x,settings)
  y = bsxfun(@minus,x,settings.xoffset);
  y = bsxfun(@times,y,settings.gain);
  y = bsxfun(@plus,y,settings.ymin);
end

% Sigmoid Symmetric Transfer Function
function a = tansig_apply(n,~)
  a = 2 ./ (1 + exp(-2*n)) - 1;
end

% Map Minimum and Maximum Output Reverse-Processing Function
function x = mapminmax_reverse(y,settings)
  x = bsxfun(@minus,y,settings.ymin);
  x = bsxfun(@rdivide,x,settings.gain);
  x = bsxfun(@plus,x,settings.xoffset);
end
